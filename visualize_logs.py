#!/usr/bin/env python3
"""
visualize_logs.py â€” ChromaDBã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’UMAPã§2æ¬¡å…ƒã«æŠ•å½±ã—ã¦æ•£å¸ƒå›³ã‚’æç”»ã™ã‚‹

å‰æ:
  - search_logs.py ã§ chroma_db/ ãŒæ§‹ç¯‰æ¸ˆã¿ã§ã‚ã‚‹ã“ã¨
  - pip install umap-learn matplotlib

ä½¿ã„æ–¹:
  python visualize_logs.py                â†’ æ•£å¸ƒå›³ã‚’è¡¨ç¤º
  python visualize_logs.py --save         â†’ umap_logs.png ã¨ã—ã¦ä¿å­˜
  python visualize_logs.py --rebuild      â†’ DBå†æ§‹ç¯‰ã—ã¦ã‹ã‚‰å¯è¦–åŒ–
"""

import sys
import os
from pathlib import Path
from dotenv import load_dotenv
from google import genai
from google.genai import types
import chromadb
import numpy as np

load_dotenv()

# --- è¨­å®šï¼ˆsearch_logs.py ã¨å…±é€šï¼‰---
EMBEDDING_MODEL = "gemini-embedding-001"
OUTPUT_DIMENSIONALITY = 768
LOG_DIR = Path("logs")
DB_DIR = Path("chroma_db")
COLLECTION_NAME = "et1_logs"
CHUNK_SIZE = 500

# --- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ¥ã®è¡¨ç¤ºè¨­å®š ---
EPISODE_COLORS = {
    "ET1_ep00": "#888888",   # è¦šé†’ï¼ˆã‚°ãƒ¬ãƒ¼ï¼‰
    "ET1_ep01": "#4CAF50",   # Linux ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆç·‘ï¼‰
    "ET1_ep01x": "#81C784",  # å¤–ä¼ï¼ˆè–„ç·‘ï¼‰
    "ET1_ep02": "#2196F3",   # ABCæ˜Ÿç³»ãƒ»APIã‚­ãƒ¼ï¼ˆé’ï¼‰
    "ET1_ep03": "#FF9800",   # ç¿»è¨³ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ï¼‰
    "ET1_ep04": "#E91E63",   # æ°´ç€å›ãƒ»Visionï¼ˆãƒ”ãƒ³ã‚¯ï¼‰
    "ET1_ep05": "#9C27B0",   # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ»ãƒ™ã‚¯ãƒˆãƒ«DBï¼ˆç´«ï¼‰
}

EPISODE_LABELS = {
    "ET1_ep00": "EP00: è¦šé†’",
    "ET1_ep01": "EP01: Linux ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—",
    "ET1_ep01x": "EP01x: ç’°å¢ƒæ§‹ç¯‰å¤–ä¼",
    "ET1_ep02": "EP02: APIã‚­ãƒ¼å–å¾—",
    "ET1_ep03": "EP03: ç¿»è¨³ãƒ—ãƒ­ã‚°ãƒ©ãƒ ",
    "ET1_ep04": "EP04: Visionãƒ»ç”»åƒåˆ†é¡",
    "ET1_ep05": "EP05: ãƒ™ã‚¯ãƒˆãƒ«DB",
}


# --- search_logs.py ã‹ã‚‰æµç”¨ ---
def get_embeddings(texts, client, task_type="RETRIEVAL_DOCUMENT"):
    result = client.models.embed_content(
        model=EMBEDDING_MODEL,
        contents=texts,
        config=types.EmbedContentConfig(
            task_type=task_type,
            output_dimensionality=OUTPUT_DIMENSIONALITY,
        ),
    )
    return [e.values for e in result.embeddings]


def load_and_chunk(log_dir):
    docs, ids, metadatas = [], [], []
    for md_file in sorted(log_dir.glob("ET1_ep*.md")):
        text = md_file.read_text(encoding="utf-8")
        paragraphs = text.split("\n\n")
        chunk = ""
        chunk_idx = 0
        for para in paragraphs:
            if len(chunk) + len(para) < CHUNK_SIZE:
                chunk += para + "\n\n"
            else:
                if chunk.strip():
                    doc_id = f"{md_file.stem}_chunk{chunk_idx:03d}"
                    docs.append(chunk.strip())
                    ids.append(doc_id)
                    metadatas.append({
                        "source": md_file.name,
                        "episode": md_file.stem,
                        "chunk_index": chunk_idx,
                    })
                    chunk_idx += 1
                chunk = para + "\n\n"
        if chunk.strip():
            doc_id = f"{md_file.stem}_chunk{chunk_idx:03d}"
            docs.append(chunk.strip())
            ids.append(doc_id)
            metadatas.append({
                "source": md_file.name,
                "episode": md_file.stem,
                "chunk_index": chunk_idx,
            })
    return docs, ids, metadatas


def build_db(docs, ids, metadatas, genai_client):
    print(f"ğŸ“¦ {len(docs)} ãƒãƒ£ãƒ³ã‚¯ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    print(f"ğŸ”„ {EMBEDDING_MODEL} ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­ï¼ˆ{OUTPUT_DIMENSIONALITY}æ¬¡å…ƒï¼‰...")
    all_embeddings = []
    batch_size = 100
    for i in range(0, len(docs), batch_size):
        batch = docs[i : i + batch_size]
        embeddings = get_embeddings(batch, genai_client, task_type="RETRIEVAL_DOCUMENT")
        all_embeddings.extend(embeddings)
        print(f"   {min(i + batch_size, len(docs))}/{len(docs)} å®Œäº†")

    client = chromadb.PersistentClient(path=str(DB_DIR))
    try:
        client.delete_collection(COLLECTION_NAME)
    except Exception:
        pass
    collection = client.create_collection(
        name=COLLECTION_NAME,
        metadata={"description": "ElmarTail One èˆªæµ·ãƒ­ã‚°"},
    )
    collection.add(
        documents=docs, ids=ids,
        metadatas=metadatas, embeddings=all_embeddings,
    )
    print(f"âœ… ChromaDBã«æ ¼ç´å®Œäº†ï¼ˆ{collection.count()} ãƒãƒ£ãƒ³ã‚¯ â†’ {DB_DIR}/ï¼‰")
    return client, collection


# --- UMAPå¯è¦–åŒ– ---
def visualize(collection, save=False):
    import umap
    import matplotlib
    import matplotlib.pyplot as plt
    from matplotlib import font_manager

    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆjapanize_matplotlibä¸è¦ï¼‰
    # macOS: ãƒ’ãƒ©ã‚®ãƒã€Linux: Noto Sans CJKã€Windows: Yu Gothic
    jp_fonts = ["Hiragino Sans", "Hiragino Maru Gothic Pro",
                "Noto Sans CJK JP", "Noto Sans JP",
                "Yu Gothic", "Meiryo", "IPAexGothic"]
    for font_name in jp_fonts:
        try:
            font_manager.findfont(font_name, fallback_to_default=False)
            matplotlib.rcParams["font.family"] = font_name
            break
        except ValueError:
            continue

    # ChromaDBã‹ã‚‰å…¨ãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    all_data = collection.get(include=["embeddings", "metadatas"])
    embeddings = np.array(all_data["embeddings"])
    metadatas = all_data["metadatas"]

    print(f"ğŸ”„ UMAPå®Ÿè¡Œä¸­... {embeddings.shape[0]} ãƒãƒ£ãƒ³ã‚¯ Ã— {embeddings.shape[1]} æ¬¡å…ƒ â†’ 2æ¬¡å…ƒ")

    # UMAP ã§2æ¬¡å…ƒã«æŠ•å½±
    reducer = umap.UMAP(
        n_components=2,
        n_neighbors=10,
        min_dist=0.1,
        metric="cosine",
        random_state=42,
    )
    coords = reducer.fit_transform(embeddings)

    print("âœ… UMAPå®Œäº†")

    # --- æ•£å¸ƒå›³ã‚’æç”» ---
    fig, ax = plt.subplots(figsize=(12, 8))
    fig.patch.set_facecolor("#1a1a2e")
    ax.set_facecolor("#1a1a2e")

    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ¥ã«ãƒ—ãƒ­ãƒƒãƒˆ
    episodes = sorted(set(m["episode"] for m in metadatas))
    for ep in episodes:
        mask = [m["episode"] == ep for m in metadatas]
        x = coords[mask, 0]
        y = coords[mask, 1]
        color = EPISODE_COLORS.get(ep, "#FFFFFF")
        label = EPISODE_LABELS.get(ep, ep)
        ax.scatter(x, y, c=color, label=label, s=60, alpha=0.8, edgecolors="white", linewidth=0.3)

    ax.set_title("ElmarTail One èˆªæµ·ãƒ­ã‚° â€” 768æ¬¡å…ƒã®æ˜Ÿç©ºã‚’2æ¬¡å…ƒã«", fontsize=16, color="white", pad=15)
    ax.set_xlabel("")
    ax.set_ylabel("")
    ax.set_xticks([])
    ax.set_yticks([])
    for spine in ax.spines.values():
        spine.set_visible(False)

    legend = ax.legend(
        loc="upper right", fontsize=10,
        facecolor="#2a2a4a", edgecolor="#555",
        labelcolor="white",
        bbox_to_anchor=(1.0, 1.0),
    )
    legend.get_frame().set_alpha(0.9)

    plt.tight_layout()

    if save:
        output_path = "umap_logs.png"
        plt.savefig(output_path, dpi=150, facecolor=fig.get_facecolor())
        print(f"ğŸ’¾ ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    else:
        plt.show()


def main():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ.env ã‚’ç¢ºèªï¼‰")
        sys.exit(1)

    genai_client = genai.Client(api_key=api_key)

    # DBæ§‹ç¯‰ or èª­ã¿è¾¼ã¿
    if not DB_DIR.exists() or "--rebuild" in sys.argv:
        docs, ids, metadatas = load_and_chunk(LOG_DIR)
        if not docs:
            print(f"âŒ {LOG_DIR}/ ã«ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        db_client, collection = build_db(docs, ids, metadatas, genai_client)
    else:
        print(f"ğŸ“‚ æ—¢å­˜DBèª­ã¿è¾¼ã¿: {DB_DIR}/")
        db_client = chromadb.PersistentClient(path=str(DB_DIR))
        collection = db_client.get_collection(COLLECTION_NAME)
        print(f"   {collection.count()} ãƒãƒ£ãƒ³ã‚¯")

    # å¯è¦–åŒ–
    save = "--save" in sys.argv
    visualize(collection, save=save)


if __name__ == "__main__":
    main()
