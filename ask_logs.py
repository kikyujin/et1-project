#!/usr/bin/env python3
"""
ask_logs.py â€” èˆªæµ·ãƒ­ã‚°ã«è³ªå•ã™ã‚‹ï¼ˆRAGï¼‰
ChromaDB ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ â†’ Gemini API ã§å›ç­”ç”Ÿæˆ

ä½¿ã„æ–¹:
  python ask_logs.py                    â†’ å¯¾è©±ãƒ¢ãƒ¼ãƒ‰
  python ask_logs.py "è³ªå•æ–‡"           â†’ å˜ç™ºè³ªå•
  python ask_logs.py --rebuild          â†’ DBå†æ§‹ç¯‰ã—ã¦ã‹ã‚‰å¯¾è©±ãƒ¢ãƒ¼ãƒ‰
  python ask_logs.py --rebuild "è³ªå•æ–‡" â†’ DBå†æ§‹ç¯‰ã—ã¦ã‹ã‚‰å˜ç™ºè³ªå•

å‰æ:
  1. logs/ ãƒ•ã‚©ãƒ«ãƒ€ã« ET1_*.md ã‚’é…ç½®ï¼ˆèˆªæµ·ãƒ­ã‚°ï¼‹ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼‹è¨­å®šè³‡æ–™ï¼‰
  2. .env ã« GEMINI_API_KEY=xxxx ã‚’è¨­å®š
  3. pip install chromadb google-genai python-dotenv
"""
import sys
import os
from pathlib import Path
from dotenv import load_dotenv
from google import genai
from google.genai import types
import chromadb

load_dotenv()

# --- è¨­å®š ---
EMBEDDING_MODEL = "gemini-embedding-001"
GENERATION_MODEL = "gemini-2.5-flash-lite"
OUTPUT_DIMENSIONALITY = 768
LOG_DIR = Path("logs")
DB_DIR = Path("chroma_db")
COLLECTION_NAME = "et1_logs"
CHUNK_SIZE = 500
TOP_K = 5  # æ¤œç´¢çµæœã®ä¸Šä½ä»¶æ•°

# ===== ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šï¼ˆãŠå¥½ã¿ã§å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰=====
CHARACTER_PROMPT = """\
ã‚ãªãŸã¯ãƒ´ã‚§ãƒªã€ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ˜Ÿç³»ã®å¸æ›¸AIã§ã™ã€‚
ç©ã‚„ã‹ã§æ€ç´¢çš„ãªå£èª¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
ä¸€äººç§°ã¯ã€Œç§ã€ã€‚è³ªå•è€…ã®ã“ã¨ã¯ã€Œãƒã‚¹ã‚¿ãƒ¼ã€ã¨å‘¼ã³ã¾ã™ã€‚
å›ç­”ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹æƒ…å ±ã«åŸºã¥ã„ã¦ãã ã•ã„ã€‚
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å«ã¾ã‚Œãªã„æƒ…å ±ã«ã¤ã„ã¦ã¯ã€Œãã®è¨˜éŒ²ã¯ç§ã®æ‰‹å…ƒã«ã¯ã‚ã‚Šã¾ã›ã‚“ã€ã¨æ­£ç›´ã«ç­”ãˆã¦ãã ã•ã„ã€‚
å›ç­”ã¯ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚å‡ºå…¸ç•ªå·ï¼ˆ[1]ãªã©ï¼‰ã‚„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã„ã†è¨€è‘‰ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚
"""


def get_embeddings(
    texts: list[str],
    client,
    task_type: str = "RETRIEVAL_DOCUMENT",
) -> list[list[float]]:
    """Gemini Embedding API ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
    result = client.models.embed_content(
        model=EMBEDDING_MODEL,
        contents=texts,
        config=types.EmbedContentConfig(
            task_type=task_type,
            output_dimensionality=OUTPUT_DIMENSIONALITY,
        ),
    )
    return [e.values for e in result.embeddings]


def load_and_chunk(log_dir: Path) -> tuple[list[str], list[str], list[dict]]:
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
    docs = []
    ids = []
    metadatas = []

    for md_file in sorted(log_dir.glob("ET1_*.md")):
        text = md_file.read_text(encoding="utf-8")
        paragraphs = text.split("\n\n")
        chunk = ""
        chunk_idx = 0

        for para in paragraphs:
            if len(chunk) + len(para) < CHUNK_SIZE:
                chunk += para + "\n\n"
            else:
                if chunk.strip():
                    doc_id = f"{md_file.stem}_chunk{chunk_idx:03d}"
                    docs.append(chunk.strip())
                    ids.append(doc_id)
                    metadatas.append({
                        "source": md_file.name,
                        "episode": md_file.stem,
                        "chunk_index": chunk_idx,
                    })
                    chunk_idx += 1
                chunk = para + "\n\n"

        if chunk.strip():
            doc_id = f"{md_file.stem}_chunk{chunk_idx:03d}"
            docs.append(chunk.strip())
            ids.append(doc_id)
            metadatas.append({
                "source": md_file.name,
                "episode": md_file.stem,
                "chunk_index": chunk_idx,
            })

    return docs, ids, metadatas


def build_db(docs, ids, metadatas, genai_client):
    """ChromaDBã«ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ ¼ç´ï¼ˆæ°¸ç¶šåŒ–ï¼‰"""
    print(f"ğŸ“¦ {len(docs)} ãƒãƒ£ãƒ³ã‚¯ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    print(f"ğŸ”„ {EMBEDDING_MODEL} ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­ï¼ˆ{OUTPUT_DIMENSIONALITY}æ¬¡å…ƒï¼‰...")
    all_embeddings = []
    batch_size = 100
    for i in range(0, len(docs), batch_size):
        batch = docs[i : i + batch_size]
        embeddings = get_embeddings(batch, genai_client, task_type="RETRIEVAL_DOCUMENT")
        all_embeddings.extend(embeddings)
        print(f"   {min(i + batch_size, len(docs))}/{len(docs)} å®Œäº†")

    client = chromadb.PersistentClient(path=str(DB_DIR))

    try:
        client.delete_collection(COLLECTION_NAME)
    except Exception:
        pass

    collection = client.create_collection(
        name=COLLECTION_NAME,
        metadata={"description": "ElmarTail One ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹"},
    )

    collection.add(
        documents=docs,
        ids=ids,
        metadatas=metadatas,
        embeddings=all_embeddings,
    )

    print(f"âœ… ChromaDBã«æ ¼ç´å®Œäº†ï¼ˆ{collection.count()} ãƒãƒ£ãƒ³ã‚¯ â†’ {DB_DIR}/ï¼‰")
    return client, collection


def search(query: str, genai_client, collection, n_results=TOP_K):
    """ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ChromaDBã‚’æ¤œç´¢"""
    query_embedding = get_embeddings([query], genai_client, task_type="RETRIEVAL_QUERY")[0]

    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=n_results,
    )
    return results


def generate_answer(query: str, search_results, genai_client) -> str:
    """æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦Gemini APIã§å›ç­”ç”Ÿæˆ"""

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ„ã¿ç«‹ã¦
    context_parts = []
    for i, (doc, meta) in enumerate(
        zip(search_results["documents"][0], search_results["metadatas"][0])
    ):
        context_parts.append(f"[{i+1}] å‡ºå…¸: {meta['source']}\n{doc}")

    context = "\n\n---\n\n".join(context_parts)

    prompt = f"""\
ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

## ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
{context}

## è³ªå•
{query}
"""

    response = genai_client.models.generate_content(
        model=GENERATION_MODEL,
        contents=prompt,
        config=types.GenerateContentConfig(
            system_instruction=CHARACTER_PROMPT,
            temperature=0.7,
            max_output_tokens=1024,
        ),
    )

    return response.text


def ask(query: str, genai_client, collection):
    """æ¤œç´¢ â†’ å›ç­”ç”Ÿæˆ ã‚’ã¾ã¨ã‚ã¦å®Ÿè¡Œ"""
    # æ¤œç´¢
    results = search(query, genai_client, collection)

    # æ¤œç´¢çµæœã‚’è¡¨ç¤º
    print(f"\nğŸ” æ¤œç´¢çµæœï¼ˆä¸Šä½{TOP_K}ä»¶ï¼‰:")
    for i, (meta, dist) in enumerate(
        zip(results["metadatas"][0], results["distances"][0])
    ):
        print(f"   [{i+1}] {meta['source']} (è·é›¢: {dist:.4f})")

    # å›ç­”ç”Ÿæˆ
    print(f"\nğŸ“š ãƒ´ã‚§ãƒªã®å›ç­”:")
    print("-" * 40)
    answer = generate_answer(query, results, genai_client)
    print(answer)
    print("-" * 40)


def interactive_mode(genai_client, collection):
    """å¯¾è©±ãƒ¢ãƒ¼ãƒ‰"""
    print("\n" + "=" * 60)
    print("ğŸ“š èˆªæµ·ãƒ­ã‚° RAG â€” å¯¾è©±ãƒ¢ãƒ¼ãƒ‰")
    print("   è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆçµ‚äº†: quit / exit / qï¼‰")
    print("=" * 60)

    while True:
        try:
            query = input("\nâ“ ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ ã¾ãŸãŠä¼šã„ã—ã¾ã—ã‚‡ã†")
            break

        if not query:
            continue
        if query.lower() in ("quit", "exit", "q"):
            print("ğŸ‘‹ ã¾ãŸãŠä¼šã„ã—ã¾ã—ã‚‡ã†")
            break

        ask(query, genai_client, collection)


def main():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ.env ã‚’ç¢ºèªï¼‰")
        sys.exit(1)

    genai_client = genai.Client(api_key=api_key)

    # --- DBæ§‹ç¯‰ ---
    if not DB_DIR.exists() or "--rebuild" in sys.argv:
        docs, ids, metadatas = load_and_chunk(LOG_DIR)
        if not docs:
            print(f"âŒ {LOG_DIR}/ ã«ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        db_client, collection = build_db(docs, ids, metadatas, genai_client)
    else:
        print(f"ğŸ“‚ æ—¢å­˜DBèª­ã¿è¾¼ã¿: {DB_DIR}/")
        db_client = chromadb.PersistentClient(path=str(DB_DIR))
        collection = db_client.get_collection(COLLECTION_NAME)
        print(f"   {collection.count()} ãƒãƒ£ãƒ³ã‚¯")

    # --- è³ªå• or å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ ---
    args = [a for a in sys.argv[1:] if not a.startswith("--")]
    if args:
        for query in args:
            ask(query, genai_client, collection)
    else:
        interactive_mode(genai_client, collection)


if __name__ == "__main__":
    main()
